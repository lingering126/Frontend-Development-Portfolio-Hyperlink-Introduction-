Hardware

The front of the headset featuring glass covering the "EyeSight" display and cameras
Apple Vision Pro comprises approximately 300 components.[40] It has a curved laminated glass display on the front, an aluminum frame on its sides, a flexible cushion on the inside, and a removable, adjustable headband. The frame contains five sensors, six microphones, and 12 cameras. Users see two 3660x3200 pixel[4] 1.41-inch (3.6 cm) micro-OLED displays with a total of 23 megapixels usually running at 90 FPS through the lens but can automatically adjust to 96 or 100 FPS based on the content being shown. The eyes are tracked by a system of LEDs and infrared cameras, which form the basis of the device's iris scanner named Optic ID (used for authentication, like the iPhone's Face ID). Horizontally-mounted motors adjust lenses for individual eye positions to ensure clear and focused images that precisely track eye movements. Sensors such as accelerometers and gyroscopes track facial movements, minimizing discrepancies between the real world and the projected image.[40] Custom optical inserts are supported for users with prescription glasses, which will attach magnetically to the main lens and are developed in partnership with Zeiss. The device's bone conduction speaker is inside the headband and is placed directly over the user's ears. It can also virtualize surround sound.[41][13][40] Two cooling fans about 4 cm (1.6 in) in diameter are placed near the eye positions to help with heat dissipation due to high-speed processing of data. An active noise control function counters distracting noises, including the fan sounds.[40] During the ordering process, users must scan their face using an iPhone or iPad with Face ID for fitting purposes; this can be done via the Apple Store app or at an Apple Store retail location.[42][43]

Apple Vision Pro uses the Apple M2 system on a chip. It is accompanied by a co-processor known as Apple R1, which is used for real-time sensor input processing. The device can be purchased with three internal storage configurations: 256 GB, 512 GB, and 1 TB.[36] It can be powered by an external power supply, a USB-C port on a Mac, or a battery pack rated for two and a half hours of use.[44][12] The battery pack connects to the headset using an unremovable 12-pin locking variant of the Lightning connector.[45]

The user's face is scanned by the headset during setup to generate a personaâ€”a realistic avatar used by OS features.[46] One such feature is "EyeSight", an outward-facing display which displays the eyes of the user's persona. Its eyes appear dimmed when in AR and obscured when in full immersion to indicate the user's environmental awareness. When someone else approaches or speaks, even if the user is fully immersed, EyeSight shows their persona's virtual eyes normally and makes the other person visible.[44][47]

A digital crown dial on the headset is used to control the amount of virtual background occupying the user's field of view, ranging from a mixed-reality view where apps and media appear to float in the user's real-world surroundings, to completely hiding the user's surroundings.[48][44]

Accessories
First-party consumer accessories for Apple Vision Pro include a US$199 travel bag, $99 Apple-manufactured Zeiss optical inserts for users with farsightedness,[49] a $199 light seal, and a $29 light seal cushion. The only official third-party accessory available at launch is a battery holder made by Belkin.[50][51][52]

A first-party adapter costing $299 is available and can only be purchased by registered, paid Apple Developer accounts, that replaces the right head-strap connection and adds a USB-C port for use by developers.[53][54][55] Code from diagnostics tools have revealed that the adapter is capable of interacting with Apple Vision Pro in a diagnostic mode.[56]

Software
Main article: visionOS
Apple Vision Pro runs visionOS (internally called xrOS before a last-minute change ahead of WWDC[57]), which is derived primarily from iOS core frameworks (including UIKit, SwiftUI, and ARKit), and MR-specific frameworks for foveated rendering and real-time interaction.[2][32]

The operating system uses a 3D user interface navigated via finger tracking, eye tracking, and speech recognition. Users can select elements by looking at it and pinching two fingers together, move the element by moving their pinched fingers, and scroll by flicking their wrist. Apps are displayed in floating windows that can be arranged in 3D space. visionOS supports a virtual keyboard for text input, the Siri virtual assistant, and external Bluetooth peripherals including Magic Keyboard, Magic Trackpad, and gamepads.[44][58] visionOS supports screen mirroring to other Apple devices using AirPlay.[59] visionOS can mirror the primary display of a macOS device via the "Mac Virtual Display" feature; the Mac can also be controlled using peripherals paired with the headset.[59]

visionOS supports vision apps from App Store, and is backward compatible with selected iOS and iPadOS apps; developers are allowed to opt out from visionOS compatibility.[60] Netflix, Spotify, and YouTube notably announced that they would not release visionOS apps at launch, nor support their iOS apps on the platform, and directed users to use their web versions in Safari.[61] Analysts suggested that this may have resulted from the companies' strained relationships with Apple over App Store policies such as mandatory 30% revenue sharing, including associated antitrust allegations.[62][63] In an interview, Netflix co-CEO Greg Peters stated that Apple Vision Pro was too niche to for the company to support at this time, but that "we're always in discussions with Apple to try and figure that out".[64] A YouTube spokesperson

Reference: https://en.wikipedia.org/wiki/Apple_Vision_Pro